{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HF1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matech96/DeepLearningAVizualisInformatikaban/blob/master/HF1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyV6HUixpnJ7",
        "colab_type": "code",
        "outputId": "65a35e33-43f8-4074-bfd2-5cbf3a3e2d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install --upgrade tqdm==4.41.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/9e/db4e1e3036e045a25d5c37617ded31a673a61f4befc62c5231818810b3a7/pytorch-lightning-0.7.1.tar.gz (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 9.1MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.35.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/55/fd9170ba08a1a64a18a7f8a18f088037316f2a41be04d2fe6ece5a653e8f/tqdm-4.43.0-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.17.5)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.15.0)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 77.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (45.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.27.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.0.0)\n",
            "Building wheels for collected packages: pytorch-lightning, future\n",
            "  Building wheel for pytorch-lightning (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-lightning: filename=pytorch_lightning-0.7.1-cp36-none-any.whl size=145306 sha256=50d6d34a79d7920e4e5056e1f92960880fd9e4daa893263928536e9863716248\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/93/61/14094d2116ff739513dda993007501ae5701b78386b39d5912\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=8ba2dc595beff03c82dd2d35d1c68d4446d0171aaeb86d3a53e8bf1d9c716b5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built pytorch-lightning future\n",
            "Installing collected packages: tqdm, future, pytorch-lightning\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed future-0.18.2 pytorch-lightning-0.7.1 tqdm-4.43.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm==4.41.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c9/7fc20feac72e79032a7c8138fd0d395dc6d8812b5b9edf53c3afd0b31017/tqdm-4.41.1-py2.py3-none-any.whl (56kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 34.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 20kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 30kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 51kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.43.0\n",
            "    Uninstalling tqdm-4.43.0:\n",
            "      Successfully uninstalled tqdm-4.43.0\n",
            "Successfully installed tqdm-4.41.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjmy-bF_A3zL",
        "colab_type": "text"
      },
      "source": [
        "#Deep Learning Alkalmazása a Vizuális Informatikában \n",
        "##1. Házi feladat\n",
        "\n",
        "**Fontos tudnivalók**\n",
        "\n",
        "*   A házi feladatot önállóan kell elvégezni. Teljes megoldások máshonnan történő másolása nem elfogadható.\n",
        "*   Ez a notebook egyben megoldás és dokumentáció. Az eredményeket értékeljétek ki, printelgessetek, ahhoz fűzzetek szépen megszerkesztett kommentárokat, stb.\n",
        "*   Egy rész feladatot nem kell egyetlen kód blokkban megoldani. Sokkal szebb és struktúráltab lesz a munka, ha logikailag összetartozó egységekre bontjátok és azokat szépen egyesével magyarázzátok.\n",
        "*   A házi feladat elkészítésére 3 hét áll rendelkezésetekre. Beadni az Edu portálon lehet. A határidő Március 12. 12:00.\n",
        "\n",
        "### 1. Rész\n",
        "\n",
        "Implementálj PyTorch-ban 2D konvolúciós réteget az NN, valamint a Functional modulok használata nélkül. A réteg konstruktorának a következő bemeneti paraméterei legyenek:\n",
        "\n",
        "\n",
        "*   Kernel méret (n)\n",
        "*   Bemeneti csatornaszám (inCH)\n",
        "*   Kimeneti csatornaszám (oCH)\n",
        "\n",
        "A rétegnek legyen forward függvénye, amelyben megkap egy [inCH x H x W] méretű tenzort, ahol H és W nem ismertek előre. A kimenete pedig legyen [oCH x H x W] (használj a kernel mérethez megfelelő paddinget).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15wCG5KWA2gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class Conv():\n",
        "  def __init__(self, n, inCH, oCH):\n",
        "    self.n = n\n",
        "    self.inCH = inCH\n",
        "    self.oCH = oCH\n",
        "    self.W = torch.Tensor(np.random.randn(oCH,inCH,n,n)).requires_grad_(True)\n",
        "\n",
        "  def parameters(self):\n",
        "    yield self.W\n",
        "\n",
        "  def forward(self, x):\n",
        "    pad = self.n // 2\n",
        "    x_ = torch.zeros(1,self.inCH,x.shape[2]+2*pad,x.shape[3]+2*pad).requires_grad_(False)\n",
        "    if pad != 0:\n",
        "      x_[0, :, pad:-pad, pad:-pad] = x\n",
        "    else:\n",
        "      x_ = x\n",
        "    res = torch.zeros(1,self.oCH,x.shape[2],x.shape[3]).requires_grad_(False)\n",
        "    for i in range(x_.shape[2] - self.n + 1):\n",
        "      for j in range(x_.shape[3] - self.n + 1):\n",
        "        res[0, :, i, j] = torch.addmv(torch.zeros(self.oCH), torch.reshape(self.W, (self.oCH, -1)), torch.reshape(x_[0, :, i:i+self.n, j:j+self.n], ((-1, ))))\n",
        "    return res\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zso5Ze7NgJYy",
        "colab_type": "text"
      },
      "source": [
        "Megnézem, hogy mindenova kerül-e érték."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adhFWxjLOmEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myconv = Conv(n = 5, inCH = 3, oCH = 1)\n",
        "\n",
        "x = torch.Tensor(np.random.randn(1,3,8,8)).requires_grad_(False)\n",
        "plt.imshow(myconv.forward(x).detach().numpy()[0,0,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cICNrzbNJkkz",
        "colab_type": "text"
      },
      "source": [
        "###2. Rész\n",
        "\n",
        "Amennyiben az implementáció elkészült, ellenőrizd az implementáció helyességét a PyTorch Conv2d modulja segítségével! (Tipp: Használj többfajta konfigurációt!)\n",
        "https://pytorch.org/docs/stable/nn.html#conv2d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHvtgfNEgSNI",
        "colab_type": "text"
      },
      "source": [
        "Egyenlővé teszem a kerneleket és vizuálisan összehasonlítom az eredményt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MakKK_lrJztm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 5\n",
        "inCH = 3\n",
        "oCH = 1\n",
        "W = torch.Tensor(np.random.randn(oCH,inCH,n,n))\n",
        "x = torch.Tensor(np.random.randn(1,3,8,8)).requires_grad_(False)\n",
        "\n",
        "myconv = Conv(n = 5, inCH = 3, oCH = 1)\n",
        "with torch.no_grad():\n",
        "  myconv.W = nn.Parameter(W)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(myconv.forward(x).detach().numpy()[0,0,:,:])\n",
        "\n",
        "refconv = nn.Conv2d(3, 1, (5, 5), padding=(2, 2), bias=False)\n",
        "with torch.no_grad():\n",
        "  refconv.weight = nn.Parameter(W)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(refconv(x).detach().numpy()[0,0,:,:])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3r_3zQYgaFO",
        "colab_type": "text"
      },
      "source": [
        "Numerikus összehasonlítást végzek néhány jellemző konfigurációra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB1X5FLKX__D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in [1,3,5,7]:\n",
        "  for inCH in [1,3,8,16]:\n",
        "    for oCH in [1,3,8,16]:\n",
        "      W = torch.Tensor(np.random.randn(oCH,inCH,n,n))\n",
        "      x = torch.Tensor(np.random.randn(1,inCH,8,8)).requires_grad_(False)\n",
        "\n",
        "      myconv = Conv(n, inCH, oCH)\n",
        "      with torch.no_grad():\n",
        "        myconv.W = nn.Parameter(W)\n",
        "      myres = myconv.forward(x).detach().numpy()\n",
        "\n",
        "      refconv = nn.Conv2d(inCH, oCH, (n, n), padding=(n//2, n//2), bias=False)\n",
        "      with torch.no_grad():\n",
        "        refconv.weight = nn.Parameter(W)\n",
        "      refres = refconv(x).detach().numpy()\n",
        "\n",
        "      assert(np.all((myres - refres) < 1e-4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5HXFkqaKYAp",
        "colab_type": "text"
      },
      "source": [
        "###3. Rész\n",
        "\n",
        "Hozz létre egy egy bemeneti csatornás konvolúciós réteget, amelynek az egyes kimeneti csatornákhoz tartozó szűrőinek súlyait inicializáld véletlenszerűen. (A kimeneti csatornák száma legyen mondjuk 3.)\n",
        "\n",
        "Ezt követően olvass be egy képet, szürkeárnyalatosítsd, és futtass le OpenCV segítségével 3 általad választott konvolúciós szűrőt!\n",
        "\n",
        "Végezetül tanítsd be arra a létrehozott konvolúciós réteget, hogy az OpenCV-s szűréseket minél pontosabban reprodukálni tudja. Vizsgáld meg az eredményként kapott szűrőket! (Tipp: Az OpenCV-vel szűrt képeket használd referenciaként, mondjuk a négyzetes hiba költséggel. Több képet egy tömbbe összepakolni np.stack segítségével lehet.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PO015ozLIgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from PIL import ImageFilter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aeftz0YnKJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GaussCifar(Dataset):\n",
        "  def __init__(self, offset=0):\n",
        "    self.cifar = CIFAR10(os.getcwd() + '/cifar',download=True)\n",
        "    self.offset = offset\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    index = i + self.offset\n",
        "    chFirst = lambda x: np.rollaxis(np.array(x, dtype=np.float32) / 255., 2, 0)\n",
        "    return chFirst(self.cifar[index][0]), chFirst(self.cifar[index][0].filter(ImageFilter.Kernel((3, 3), \n",
        "          (-1, -1, -1, -1, 9, -1, -1, -1, -1), 1, 0)))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LofhrWRZpfDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dl = DataLoader(GaussCifar(), batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebs2LZKoyiRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8kEejwTq65r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = next(iter(dl))\n",
        "plt.imshow(np.rollaxis(t[0][0, ].detach().numpy(), 0, 3))\n",
        "plt.show()\n",
        "plt.imshow(np.rollaxis(t[1][0, ].detach().numpy(), 0, 3))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgK3xwWliTDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.optim import Adam\n",
        "class CoolCIFAR(pl.LightningModule):  \n",
        "  def __init__(self, model):\n",
        "    super(CoolCIFAR, self).__init__()\n",
        "    self.model = model\n",
        "    self.mse = nn.MSELoss()\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.model.parameters()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(GaussCifar(), batch_size=64)\n",
        "\n",
        "  # def val_dataloader(self):\n",
        "  #   return DataLoader(GaussCifar(64), batch_size=64)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    res = self.forward(x)\n",
        "    loss = self.mse(res, y)\n",
        "    logs = {'train_loss': loss}\n",
        "    return {'loss': loss, 'log': logs}\n",
        "\n",
        "  # def validation_step(self, batch, batch_idx):\n",
        "  #   x, y = batch\n",
        "  #   res = self.forward(x)\n",
        "  #   loss = self.mse(res, y)\n",
        "  #   return {'val_loss': loss}\n",
        "\n",
        "  # def validation_end(self, outputs):\n",
        "  #   avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "  #   tensorboard_logs = {'val_loss': avg_loss}\n",
        "  #   return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1RsCByLjLi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_lightning import Trainer\n",
        "\n",
        "model = CoolCIFAR(nn.Conv2d(3, 3, (3, 3), padding=(3//2, 3//2), bias=False))\n",
        "trainer = Trainer(max_epoch=1)\n",
        "trainer.fit(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el0BmROvtMpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}