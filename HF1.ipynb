{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HF1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a20ebfb3a4b941168b9c03759536403f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53a91c0d8c0845efb253f50774bde650",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_57401577e5804880b7dd02cd537be5a9",
              "IPY_MODEL_2b6f860fcc5342e3b3a630bc8cf7fd8d"
            ]
          }
        },
        "53a91c0d8c0845efb253f50774bde650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57401577e5804880b7dd02cd537be5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_55b20bf4147f459e8e04d32b73a0386c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0931416ed5f44dcac412c3f14f03f2f"
          }
        },
        "2b6f860fcc5342e3b3a630bc8cf7fd8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c314e6cf5d0540e18bd995190de153f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:04, 41473775.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f095b90a25243e792b9ead0d4768580"
          }
        },
        "55b20bf4147f459e8e04d32b73a0386c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0931416ed5f44dcac412c3f14f03f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c314e6cf5d0540e18bd995190de153f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f095b90a25243e792b9ead0d4768580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matech96/DeepLearningAVizualisInformatikaban/blob/master/HF1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjmy-bF_A3zL",
        "colab_type": "text"
      },
      "source": [
        "#Deep Learning Alkalmazása a Vizuális Informatikában \n",
        "##1. Házi feladat\n",
        "\n",
        "**Fontos tudnivalók**\n",
        "\n",
        "*   A házi feladatot önállóan kell elvégezni. Teljes megoldások máshonnan történő másolása nem elfogadható.\n",
        "*   Ez a notebook egyben megoldás és dokumentáció. Az eredményeket értékeljétek ki, printelgessetek, ahhoz fűzzetek szépen megszerkesztett kommentárokat, stb.\n",
        "*   Egy rész feladatot nem kell egyetlen kód blokkban megoldani. Sokkal szebb és struktúráltab lesz a munka, ha logikailag összetartozó egységekre bontjátok és azokat szépen egyesével magyarázzátok.\n",
        "*   A házi feladat elkészítésére 3 hét áll rendelkezésetekre. Beadni az Edu portálon lehet. A határidő Március 12. 12:00.\n",
        "\n",
        "### 1. Rész\n",
        "\n",
        "Implementálj PyTorch-ban 2D konvolúciós réteget az NN, valamint a Functional modulok használata nélkül. A réteg konstruktorának a következő bemeneti paraméterei legyenek:\n",
        "\n",
        "\n",
        "*   Kernel méret (n)\n",
        "*   Bemeneti csatornaszám (inCH)\n",
        "*   Kimeneti csatornaszám (oCH)\n",
        "\n",
        "A rétegnek legyen forward függvénye, amelyben megkap egy [inCH x H x W] méretű tenzort, ahol H és W nem ismertek előre. A kimenete pedig legyen [oCH x H x W] (használj a kernel mérethez megfelelő paddinget).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15wCG5KWA2gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class Conv():\n",
        "  def __init__(self, n, inCH, oCH):\n",
        "    self.n = n\n",
        "    self.inCH = inCH\n",
        "    self.oCH = oCH\n",
        "    self.W = torch.Tensor(np.random.randn(oCH,inCH,n,n)).requires_grad_(True)\n",
        "\n",
        "  def parameters(self):\n",
        "    yield self.W\n",
        "\n",
        "  def forward(self, x):\n",
        "    pad = self.n // 2\n",
        "    x_ = torch.zeros(1,self.inCH,x.shape[2]+2*pad,x.shape[3]+2*pad).requires_grad_(False)\n",
        "    if pad != 0:\n",
        "      x_[0, :, pad:-pad, pad:-pad] = x\n",
        "    else:\n",
        "      x_ = x\n",
        "    res = torch.zeros(1,self.oCH,x.shape[2],x.shape[3]).requires_grad_(False)\n",
        "    for i in range(x_.shape[2] - self.n + 1):\n",
        "      for j in range(x_.shape[3] - self.n + 1):\n",
        "        res[0, :, i, j] = torch.addmv(torch.zeros(self.oCH), torch.reshape(self.W, (self.oCH, -1)), torch.reshape(x_[0, :, i:i+self.n, j:j+self.n], ((-1, ))))\n",
        "    return res\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zso5Ze7NgJYy",
        "colab_type": "text"
      },
      "source": [
        "Megnézem, hogy mindenova kerül-e érték."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adhFWxjLOmEB",
        "colab_type": "code",
        "outputId": "100f3084-b84a-4576-d4bf-5e2aee04045d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "myconv = Conv(n = 5, inCH = 3, oCH = 1)\n",
        "\n",
        "x = torch.Tensor(np.random.randn(1,3,8,8)).requires_grad_(False)\n",
        "plt.imshow(myconv.forward(x).detach().numpy()[0,0,:,:])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7e892598d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhlADyRBqIBlCDSRDqIFkCDWQzH8BEpLktxIV3tsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cICNrzbNJkkz",
        "colab_type": "text"
      },
      "source": [
        "###2. Rész\n",
        "\n",
        "Amennyiben az implementáció elkészült, ellenőrizd az implementáció helyességét a PyTorch Conv2d modulja segítségével! (Tipp: Használj többfajta konfigurációt!)\n",
        "https://pytorch.org/docs/stable/nn.html#conv2d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHvtgfNEgSNI",
        "colab_type": "text"
      },
      "source": [
        "Egyenlővé teszem a kerneleket és vizuálisan összehasonlítom az eredményt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MakKK_lrJztm",
        "colab_type": "code",
        "outputId": "78b8b1da-cac3-47cb-a12d-5724fa98130c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "n = 5\n",
        "inCH = 3\n",
        "oCH = 1\n",
        "W = torch.Tensor(np.random.randn(oCH,inCH,n,n))\n",
        "x = torch.Tensor(np.random.randn(1,3,8,8)).requires_grad_(False)\n",
        "\n",
        "myconv = Conv(n = 5, inCH = 3, oCH = 1)\n",
        "with torch.no_grad():\n",
        "  myconv.W = nn.Parameter(W)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(myconv.forward(x).detach().numpy()[0,0,:,:])\n",
        "\n",
        "refconv = nn.Conv2d(3, 1, (5, 5), padding=(2, 2), bias=False)\n",
        "with torch.no_grad():\n",
        "  refconv.weight = nn.Parameter(W)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(refconv(x).detach().numpy()[0,0,:,:])\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAC3CAYAAAA7DxSmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAK20lEQVR4nO3dX4xcdRnG8edh/wBdChWrAbelLQmi\njReUbBqxCSYQExQEL7yACIncVE1ACEYsRL0wcmFMGrxQkqaAJhR7USASUiX8TfSGsG0B027RpqF2\nCYUC8m8L3e7u68VOTSl0Zo7+zpx39PtJmnSmm3febJ8+PXvmz3FECACQ10lNLwAAaI+iBoDkKGoA\nSI6iBoDkKGoASI6iBoDkBusYOjAyEkOLziwyKwpuODg8U2yW3yi32JGRYqMkSZ4rO6+YQq8EPfLW\nm5o9NOUy07pHrqsh19W0y3UtRT206Eyd891bisyaXjxbZI4kfXLZP4vNOvneTxSbdeCLZX+wGTxU\nrsNc8mX2hf6h7duwvsygish1NeS6mna55tQHACRHUQNAchQ1ACRHUQNAcl0Vte3LbL9oe4/tdXUv\nBfQK2UY/6FjUtgck/VrSVyWtlHSN7ZV1LwbUjWyjX3RzRL1a0p6I2BsR05I2S7qq3rWAniDb6Avd\nFPWopP3H3J5s3fchttfaHrc9Pjs1VWo/oE4ds02ukUGxJxMjYkNEjEXE2MBI4bckAQ0h18igm6J+\nWdLSY24vad0H9Duyjb7QTVE/K+k82ytsD0u6WtLD9a4F9ATZRl/o+FkfETFj+wZJj0oakHRPROys\nfTOgZmQb/aKrD2WKiK2Stta8C9BzZBv9gHcmAkByFDUAJEdRA0BytVw4IIZCh0eni8w664lyK746\nW+5D0b/w/X3FZr15cHGxWZJ0yuMLi81678uHis0aeqHM65CLfuh7BeS6GnJdTbtcc0QNAMlR1ACQ\nHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUN\nAMlR1ACQHEUNAMlR1ACQXC2X4vK0deq+4SKzfnHHb4rMkaTbf/idYrP27z632Ky5s8peW2rdLfcX\nm/Xb1RcUm/XiTz9fZM5cLantjFxXQ66raZdrjqgBIDmKGgCSo6gBIDmKGgCSo6gBIDmKGgCS61jU\ntpfafsr2Lts7bd/Ui8WAupFt9ItuXpE6I+kHEbHd9kJJ22w/FhG7at4NqBvZRl/oeEQdEa9ExPbW\n79+VNCFptO7FgLqRbfSLSueobS+XtErSMx/zZ2ttj9senz00VWY7oEdOlG1yjQy6Lmrbp0l6QNLN\nEfHO8X8eERsiYiwixgYWjJTcEahVu2yTa2TQVVHbHtJ8kDdFxIP1rgT0DtlGP+jmVR+WdLekiYhY\nX/9KQG+QbfSLbo6o10i6TtIltp9r/fpazXsBvUC20Rc6vjwvIv4iyT3YBegpso1+wTsTASA5ihoA\nkqOoASC5Wi5qFEOh90dnisy649xyl8x560cDxWYNv13uMkOLX5grNkuSfv72t4rNeu9ns8VmnfO5\nA0XmvH7qkSJzqiLX1ZDratrlmiNqAEiOogaA5ChqAEiOogaA5ChqAEiOogaA5ChqAEiOogaA5Chq\nAEiOogaA5ChqAEiOogaA5ChqAEiOogaA5ChqAEiOogaA5ChqAEiOogaA5Gq5FNdJH1in7y4zevqx\nZUXmSNKhVz4oN6vYJOnwyOGC06SFDy0sNmv0iXeLzXrpys8UmXPkvaEic6oi19WQ62ra5ZojagBI\njqIGgOQoagBIjqIGgOQoagBIjqIGgOS6LmrbA7Z32H6kzoWAXiLX6AdVjqhvkjRR1yJAQ8g10uuq\nqG0vkXS5pI31rgP0DrlGv+j2iPpOSbdKmjvRF9hea3vc9vjs+1NFlgNqRq7RFzoWte0rJL0WEdva\nfV1EbIiIsYgYGzh1pNiCQB3INfpJN0fUayRdafslSZslXWL7vlq3AupHrtE3OhZ1RNwWEUsiYrmk\nqyU9GRHX1r4ZUCNyjX7C66gBILlKn9kYEU9LerqWTYCGkGtkxxE1ACRHUQNAchQ1ACRHUQNAcrVc\nMzEGpcNnRplZ6z9dZI4kfeknfy826/mHVhabNTd4SrFZknR4UblZf9x6f7FZl1/09SJzDrwxXWRO\nVeS6GnJdTbtcc0QNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUN\nAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQXD2X4jpJmllQ5pJFk5cOFJkjSfte+Gyx\nWSt/v6/YrPP+8GqxWZI0PVfur3X17d8rNmtsy44ic8avmykypypyXQ25rqZdrjmiBoDkKGoASI6i\nBoDkKGoASI6iBoDkuipq24tsb7G92/aE7YvqXgzoBbKNftDt611+JelPEfFN28OSFtS4E9BLZBvp\ndSxq22dIuljStyUpIqYlTde7FlA/so1+0c2pjxWSDkq61/YO2xttjxz/RbbX2h63PT47NVV8UaAG\nHbNNrpFBN0U9KOlCSXdFxCpJU5LWHf9FEbEhIsYiYmxg5CM9DmTUMdvkGhl0U9STkiYj4pnW7S2a\nDzfQ78g2+kLHoo6IA5L22z6/ddelknbVuhXQA2Qb/aLbV33cKGlT61nxvZKur28loKfINtLrqqgj\n4jlJYzXvAvQc2UY/4J2JAJAcRQ0AyVHUAJAcRQ0AydVyKS7PSsNvl/k/wLNFxkiSZqfK/b+068ej\nxWb9Y/OyYrMk6dDZc8VmnbzUxWY9/8sLisx5/8DTReZURa6rIdfVtMs1R9QAkBxFDQDJUdQAkBxF\nDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJ\nUdQAkBxFDQDJOSLKD7UPStrX4csWS3q9+IP/99irmib2WhYRn+rxY3aba4m/q6rYa94Jc11LUXfD\n9nhEjDXy4G2wVzVZ92pS1u8Je1WTaS9OfQBAchQ1ACTXZFFvaPCx22GvarLu1aSs3xP2qibNXo2d\nowYAdIdTHwCQXCNFbfsy2y/a3mN7XRM7HM/2UttP2d5le6ftm5re6SjbA7Z32H6k6V2OZXuR7S22\nd9uesH1R0zs1iVxXlzHbGXPd81Mftgck/U3SVyRNSnpW0jURsauni3x0r7MlnR0R220vlLRN0jea\n3kuSbN8iaUzS6RFxRdP7HGX7d5L+HBEbbQ9LWhARbzW9VxPI9X8mY7Yz5rqJI+rVkvZExN6ImJa0\nWdJVDezxIRHxSkRsb/3+XUkTkkab3UqyvUTS5ZI2Nr3LsWyfIeliSXdLUkRMNx3mhpHrijJmO2uu\nmyjqUUn7j7k9qSTBOcr2ckmrJD3T7CaSpDsl3SpprulFjrNC0kFJ97Z+dN1oe6TppRpErqvLmO2U\nuebJxOPYPk3SA5Jujoh3Gt7lCkmvRcS2Jvc4gUFJF0q6KyJWSZqSlOK8LD4qU65b+2TNdspcN1HU\nL0taesztJa37Gmd7SPNh3hQRDza9j6Q1kq60/ZLmf5S+xPZ9za70b5OSJiPi6NHZFs0H/P8Vua4m\na7ZT5rqJon5W0nm2V7RO1F8t6eEG9vgQ29b8eamJiFjf9D6SFBG3RcSSiFiu+e/TkxFxbcNrSZIi\n4oCk/bbPb911qaQUT1A1hFxXkDXbWXM92OsHjIgZ2zdIelTSgKR7ImJnr/f4GGskXSfpr7afa913\ne0RsbXCn7G6UtKlVTHslXd/wPo0h1/9T0uWadyYCQHI8mQgAyVHUAJAcRQ0AyVHUAJAcRQ0AyVHU\nAJAcRQ0AyVHUAJDcvwCBej19Y8QO/gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3r_3zQYgaFO",
        "colab_type": "text"
      },
      "source": [
        "Numerikus összehasonlítást végzek néhány jellemző konfigurációra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB1X5FLKX__D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in [1,3,5,7]:\n",
        "  for inCH in [1,3,8,16]:\n",
        "    for oCH in [1,3,8,16]:\n",
        "      W = torch.Tensor(np.random.randn(oCH,inCH,n,n))\n",
        "      x = torch.Tensor(np.random.randn(1,inCH,8,8)).requires_grad_(False)\n",
        "\n",
        "      myconv = Conv(n, inCH, oCH)\n",
        "      with torch.no_grad():\n",
        "        myconv.W = nn.Parameter(W)\n",
        "      myres = myconv.forward(x).detach().numpy()\n",
        "\n",
        "      refconv = nn.Conv2d(inCH, oCH, (n, n), padding=(n//2, n//2), bias=False)\n",
        "      with torch.no_grad():\n",
        "        refconv.weight = nn.Parameter(W)\n",
        "      refres = refconv(x).detach().numpy()\n",
        "\n",
        "      assert(np.all((myres - refres) < 1e-4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5HXFkqaKYAp",
        "colab_type": "text"
      },
      "source": [
        "###3. Rész\n",
        "\n",
        "Hozz létre egy egy bemeneti csatornás konvolúciós réteget, amelynek az egyes kimeneti csatornákhoz tartozó szűrőinek súlyait inicializáld véletlenszerűen. (A kimeneti csatornák száma legyen mondjuk 3.)\n",
        "\n",
        "Ezt követően olvass be egy képet, szürkeárnyalatosítsd, és futtass le OpenCV segítségével 3 általad választott konvolúciós szűrőt!\n",
        "\n",
        "Végezetül tanítsd be arra a létrehozott konvolúciós réteget, hogy az OpenCV-s szűréseket minél pontosabban reprodukálni tudja. Vizsgáld meg az eredményként kapott szűrőket! (Tipp: Az OpenCV-vel szűrt képeket használd referenciaként, mondjuk a négyzetes hiba költséggel. Több képet egy tömbbe összepakolni np.stack segítségével lehet.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PO015ozLIgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets import CIFAR10\n",
        "import os\n",
        "from PIL import ImageFilter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aeftz0YnKJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GaussCifar(Dataset):\n",
        "  def __init__(self):\n",
        "    self.cifar = CIFAR10(os.getcwd() + '/cifar',download=True)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return np.array(self.cifar[index][0]), np.array(self.cifar[index][0].filter(ImageFilter.Kernel((3, 3), \n",
        "          (-1, -1, -1, -1, 9, -1, -1, -1, -1), 1, 0)))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.cifar)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LofhrWRZpfDX",
        "colab_type": "code",
        "outputId": "0c44cb4c-dd58-4b2b-e5fd-ad63a61a9ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "a20ebfb3a4b941168b9c03759536403f",
            "53a91c0d8c0845efb253f50774bde650",
            "57401577e5804880b7dd02cd537be5a9",
            "2b6f860fcc5342e3b3a630bc8cf7fd8d",
            "55b20bf4147f459e8e04d32b73a0386c",
            "e0931416ed5f44dcac412c3f14f03f2f",
            "c314e6cf5d0540e18bd995190de153f7",
            "6f095b90a25243e792b9ead0d4768580"
          ]
        }
      },
      "source": [
        "dl = DataLoader(GaussCifar(), batch_size=64)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/cifar/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a20ebfb3a4b941168b9c03759536403f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /content/cifar/cifar-10-python.tar.gz to /content/cifar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyV6HUixpnJ7",
        "colab_type": "code",
        "outputId": "eb442f8a-d80c-4672-f6c0-fc50906f4555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install --upgrade tqdm==4.41.1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/3f/6190e07b23dc92e55b99c1f5cb9484845fa476c0fd1bc8e97fd303959293/pytorch-lightning-0.6.0.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (0.22.1)\n",
            "Collecting tqdm>=4.35.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/55/fd9170ba08a1a64a18a7f8a18f088037316f2a41be04d2fe6ece5a653e8f/tqdm-4.43.0-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.17.5)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.4.0)\n",
            "Collecting torchvision<0.5,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/e2/2b1f88a363ae37b2ba52cfb785ddfb3dd5f7e7ec9459e96fd8299b84ae39/torchvision-0.4.2-cp36-cp36m-manylinux1_x86_64.whl (10.2MB)\n",
            "\u001b[K     |████████████████████████████████| 10.2MB 64.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (0.25.3)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.15.0)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.2->pytorch-lightning) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.2->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision<0.5,>=0.4.0->pytorch-lightning) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision<0.5,>=0.4.0->pytorch-lightning) (6.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->pytorch-lightning) (2018.9)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.27.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (45.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.9.0)\n",
            "Building wheels for collected packages: pytorch-lightning, future\n",
            "  Building wheel for pytorch-lightning (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-lightning: filename=pytorch_lightning-0.6.0-cp36-none-any.whl size=116150 sha256=ddf3f8ca27e0af3c449f4b68175169e893cc21084da240413c95be49f40c4d30\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/08/72/257c395e632f8e4d68770e3935e1ba489e8a7cc82b2fd8d241\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=2e6871790263cda8478df0fcb5abc3a48a479e3fe591cf3aba2d3eafb6eb4912\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built pytorch-lightning future\n",
            "\u001b[31mERROR: torchvision 0.4.2 has requirement torch==1.3.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tqdm, torchvision, future, pytorch-lightning\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "  Found existing installation: torchvision 0.5.0\n",
            "    Uninstalling torchvision-0.5.0:\n",
            "      Successfully uninstalled torchvision-0.5.0\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed future-0.18.2 pytorch-lightning-0.6.0 torchvision-0.4.2 tqdm-4.43.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchvision",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm==4.41.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c9/7fc20feac72e79032a7c8138fd0d395dc6d8812b5b9edf53c3afd0b31017/tqdm-4.41.1-py2.py3-none-any.whl (56kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.43.0\n",
            "    Uninstalling tqdm-4.43.0:\n",
            "      Successfully uninstalled tqdm-4.43.0\n",
            "Successfully installed tqdm-4.41.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgK3xwWliTDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.optim import Adam\n",
        "class CoolCIFAR(pl.LightningModule):  \n",
        "  def __init__(self, model):\n",
        "    super(CoolCIFAR, self).__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.model.parameters()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(GaussCifar(), batch_size=64)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    res = self.forward(x)\n",
        "    loss = nn.MSELoss(res, y)\n",
        "\n",
        "    # add logging\n",
        "    logs = {'loss': loss}\n",
        "    return {'loss': loss, 'log': logs}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1RsCByLjLi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "14e3b5a3-eeb8-4d46-f9dc-479c1f9266e8"
      },
      "source": [
        "from pytorch_lightning import Trainer\n",
        "\n",
        "model = CoolCIFAR(Conv(n = 5, inCH = 3, oCH = 1))\n",
        "trainer = Trainer(gpus=1, )\n",
        "trainer.fit(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:gpu available: True, used: True\n",
            "INFO:root:VISIBLE GPUS: 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:\n",
            "Empty DataFrame\n",
            "Columns: [Name, Type, Params]\n",
            "Index: []\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0batch [00:00, ?batch/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fa8aae6ed0dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoolCIFAR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;31m# ON CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdp_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;31m# .reset() doesn't work on disabled progress bar so we should check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Epoch {epoch + 1}'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_iterable_train_dataloader\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tqdm' object has no attribute 'reset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLf4s2PLkJyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66e9cd89-b9bd-413d-de91-91a8d3490d0c"
      },
      "source": [
        "pl.__version__"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.6.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}